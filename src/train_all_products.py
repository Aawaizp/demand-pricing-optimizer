# src/train_all_products.py
# Train demand and price models for ALL products

import pandas as pd
import numpy as np
from statsforecast import StatsForecast
from statsforecast.models import AutoARIMA, AutoETS
import joblib
import os

def train_all_products():
    """Train demand models for all 20 products"""
    
    print("=" * 70)
    print("ðŸš€ TRAINING MODELS FOR ALL PRODUCTS")
    print("=" * 70)
    
    # Load data
    df = pd.read_csv('data/processed/sales_data.csv')
    df['date'] = pd.to_datetime(df['date'])
    
    all_product_ids = df['product_id'].unique()
    print(f"\nFound {len(all_product_ids)} products")
    
    # Train for each product
    for product_id in all_product_ids:
        print(f"\nðŸ“¦ Training model for Product ID: {product_id}")
        
        # Filter data
        product_data = df[df['product_id'] == product_id].copy()
        product_name = product_data['product_name'].iloc[0]
        
        print(f"   Product: {product_name}")
        
        # Aggregate to weekly
        product_data = product_data.set_index('date')
        weekly_data = product_data.resample('W').agg({
            'quantity_sold': 'sum',
            'sale_price': 'mean',
            'discount_pct': 'mean',
            'is_weekend': 'max',
            'is_festival_season': 'max',
            'competitor_price': 'mean',
            'revenue': 'sum'
        }).reset_index()
        
        # Prepare for StatsForecast
        weekly_data = weekly_data.rename(columns={'date': 'ds', 'quantity_sold': 'y'})
        weekly_data['unique_id'] = f'product_{product_id}'
        
        # Add features
        weekly_data['week_of_year'] = weekly_data['ds'].dt.isocalendar().week
        weekly_data['month'] = weekly_data['ds'].dt.month
        weekly_data['quarter'] = weekly_data['ds'].dt.quarter
        weekly_data['month_sin'] = np.sin(2 * np.pi * weekly_data['month'] / 12)
        weekly_data['month_cos'] = np.cos(2 * np.pi * weekly_data['month'] / 12)
        
        # Sort
        weekly_data = weekly_data.sort_values('ds').reset_index(drop=True)
        
        # Split
        test_weeks = 12
        train_df = weekly_data.iloc[:-test_weeks].copy()
        test_df = weekly_data.iloc[-test_weeks:].copy()
        
        # Train model
        models = [
            AutoARIMA(season_length=52),
            AutoETS(season_length=52)
        ]
        
        sf = StatsForecast(models=models, freq='W', n_jobs=1)
        sf.fit(train_df)
        
        # Save model
        os.makedirs('models', exist_ok=True)
        model_path = f'models/demand_model_weekly_product_{product_id}.pkl'
        joblib.dump(sf, model_path)
        
        # Save metadata
        metadata = {
            'product_id': product_id,
            'product_name': product_name,
            'best_model': 'AutoARIMA',
            'metrics': {'MAE': 150.0, 'MAPE': 20.0, 'R2': 0.70},  # Placeholder
            'frequency': 'weekly',
            'trained_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
            'framework': 'StatsForecast'
        }
        
        metadata_path = f'models/demand_model_weekly_product_{product_id}_metadata.pkl'
        joblib.dump(metadata, metadata_path)
        
        print(f"   âœ… Saved: {model_path}")
    
    print("\n" + "=" * 70)
    print("âœ… ALL PRODUCTS TRAINED!")
    print("=" * 70)

if __name__ == "__main__":
    train_all_products()